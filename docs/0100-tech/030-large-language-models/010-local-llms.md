# Local LLMs

You can work with local LLMs using the following tools:

- [Ollama](https://ollama.com/)
- [open-webui](https://github.com/open-webui/open-webui): A web interface for working with Ollama.
